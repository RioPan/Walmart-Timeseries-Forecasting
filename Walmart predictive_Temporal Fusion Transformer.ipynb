{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2ac8a35d",
      "metadata": {
        "id": "2ac8a35d"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import lightning as pl\n",
        "from pytorch_lightning import loggers \n",
        "import tensorflow as tf \n",
        "import tensorboard as tb \n",
        "tf.io.gfile = tb.compat.tensorflow_stub.io.gfile\n",
        "random.seed(30)\n",
        "np.random.seed(30)\n",
        "tf.random.set_seed(30)\n",
        "torch.manual_seed(30)\n",
        "\n",
        "torch.cuda.manual_seed(30)\n",
        "from pytorch_lightning.callbacks import EarlyStopping, LearningRateMonitor\n",
        "from pytorch_forecasting import Baseline, TemporalFusionTransformer, TimeSeriesDataSet\n",
        "from pytorch_forecasting.data import NaNLabelEncoder,GroupNormalizer\n",
        "from pytorch_forecasting.data.examples import generate_ar_data\n",
        "from torchmetrics import TweedieDevianceScore,RMSE\n",
        "from pytorch_forecasting.metrics import RMSE\n",
        "from pytorch_forecasting.models.temporal_fusion_transformer.tuning import optimize_hyperparameters\n",
        "import gc\n",
        "from tqdm import tqdm\n",
        "import holidays\n",
        "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "import pickle"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "fQkAdg5PFLOR"
      },
      "id": "fQkAdg5PFLOR",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GRhnq985MJnN"
      },
      "id": "GRhnq985MJnN",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9a66c2ce",
      "metadata": {
        "id": "9a66c2ce"
      },
      "outputs": [],
      "source": [
        "calendar= pd.read_csv(\"/content/calendar.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# New Section"
      ],
      "metadata": {
        "id": "wCBsV_n1tuTS"
      },
      "id": "wCBsV_n1tuTS"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "03eab56e",
      "metadata": {
        "id": "03eab56e"
      },
      "outputs": [],
      "source": [
        "calendar.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "71ef6c64",
      "metadata": {
        "id": "71ef6c64"
      },
      "outputs": [],
      "source": [
        "calendar.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "255b617b",
      "metadata": {
        "id": "255b617b"
      },
      "outputs": [],
      "source": [
        "print(calendar.event_name_1.unique())\n",
        "print(calendar.event_type_1.unique())\n",
        "print(calendar.event_name_2.unique())\n",
        "print(calendar.event_type_2.unique())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a414e409",
      "metadata": {
        "id": "a414e409"
      },
      "outputs": [],
      "source": [
        "calendar.dtypes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fd292952",
      "metadata": {
        "id": "fd292952"
      },
      "outputs": [],
      "source": [
        "calendar.date=pd.to_datetime(calendar.date)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "55a3d1de",
      "metadata": {
        "id": "55a3d1de"
      },
      "outputs": [],
      "source": [
        "calendar.dtypes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9dfebcfa",
      "metadata": {
        "id": "9dfebcfa"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b27b6160",
      "metadata": {
        "id": "b27b6160"
      },
      "outputs": [],
      "source": [
        "price=pd.read_csv(\"/content/sell_prices.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "09f26c93",
      "metadata": {
        "id": "09f26c93"
      },
      "outputs": [],
      "source": [
        "price.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "256babfe",
      "metadata": {
        "id": "256babfe"
      },
      "outputs": [],
      "source": [
        "price.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "352ef276",
      "metadata": {
        "id": "352ef276"
      },
      "outputs": [],
      "source": [
        "price.dtypes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1356df5c",
      "metadata": {
        "id": "1356df5c"
      },
      "outputs": [],
      "source": [
        "price.store_id=price.store_id.astype(\"category\")\n",
        "price.item_id=price.item_id.astype(\"category\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bed618b7",
      "metadata": {
        "id": "bed618b7"
      },
      "outputs": [],
      "source": [
        "price.dtypes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0aff8369",
      "metadata": {
        "id": "0aff8369"
      },
      "outputs": [],
      "source": [
        "df= pd.read_csv(\"/content/sales_train_evaluation.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "54a51290",
      "metadata": {
        "id": "54a51290"
      },
      "outputs": [],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b80127e7",
      "metadata": {
        "id": "b80127e7"
      },
      "outputs": [],
      "source": [
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f3711fd2",
      "metadata": {
        "id": "f3711fd2"
      },
      "outputs": [],
      "source": [
        "df.dtypes"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for d in range(1942,1970):\n",
        "    col = 'd_' + str(d)\n",
        "    df[col] = 0\n",
        "    df[col] = df[col].astype(np.int16)\n"
      ],
      "metadata": {
        "id": "UB-uNWO_cJ_J"
      },
      "id": "UB-uNWO_cJ_J",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2ab81b31",
      "metadata": {
        "id": "2ab81b31"
      },
      "outputs": [],
      "source": [
        "catcols = ['id', 'item_id', 'dept_id','store_id', 'cat_id', 'state_id']\n",
        "df = pd.melt(df,\n",
        "                  id_vars = catcols,\n",
        "                  value_vars = [col for col in df.columns if col.startswith(\"d_\")],\n",
        "                  var_name = \"d\",\n",
        "                  value_name = \"sales\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a93bb520",
      "metadata": {
        "scrolled": true,
        "id": "a93bb520"
      },
      "outputs": [],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "51b834f9",
      "metadata": {
        "id": "51b834f9"
      },
      "outputs": [],
      "source": [
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e54344f7",
      "metadata": {
        "id": "e54344f7"
      },
      "outputs": [],
      "source": [
        "l=[]\n",
        "for i in df['d']:\n",
        "  l.append(i.split('_')[1])\n",
        "df['day']=l\n",
        "df['day']=df['day'].astype(np.int16) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "18ce08ef",
      "metadata": {
        "id": "18ce08ef"
      },
      "outputs": [],
      "source": [
        "df_subset=df[df['day']>1441]"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "z3ldHqgklnyH"
      },
      "id": "z3ldHqgklnyH",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "261d402c",
      "metadata": {
        "id": "261d402c"
      },
      "outputs": [],
      "source": [
        "df_subset = df_subset.merge(calendar, on= \"d\", copy = False)\n",
        "df_subset.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a8afa098",
      "metadata": {
        "id": "a8afa098"
      },
      "outputs": [],
      "source": [
        "df_subset.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "49fd6b2d",
      "metadata": {
        "id": "49fd6b2d"
      },
      "outputs": [],
      "source": [
        "df_subset = df_subset.merge(price, on = [\"store_id\", \"item_id\", \"wm_yr_wk\"], copy = False)\n",
        "df_subset.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4b471a46",
      "metadata": {
        "id": "4b471a46"
      },
      "outputs": [],
      "source": [
        "df_subset.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b81ff977",
      "metadata": {
        "id": "b81ff977"
      },
      "outputs": [],
      "source": [
        "def reduce_mem_usage(df, verbose=True):\n",
        "    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
        "    start_mem = df.memory_usage().sum() / 1024**2    \n",
        "    for col in df.columns:\n",
        "        col_type = df[col].dtypes\n",
        "        if col_type in numerics:\n",
        "            c_min = df[col].min()\n",
        "            c_max = df[col].max()\n",
        "            if str(col_type)[:3] == 'int':\n",
        "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
        "                    df[col] = df[col].astype(np.int8)\n",
        "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
        "                    df[col] = df[col].astype(np.int16)\n",
        "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
        "                    df[col] = df[col].astype(np.int32)\n",
        "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
        "                    df[col] = df[col].astype(np.int64)  \n",
        "            else:\n",
        "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
        "                    df[col] = df[col].astype(np.float16)\n",
        "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
        "                    df[col] = df[col].astype(np.float32)\n",
        "                else:\n",
        "                    df[col] = df[col].astype(np.float64)    \n",
        "    end_mem = df.memory_usage().sum() / 1024**2\n",
        "    if verbose: print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem) / start_mem))\n",
        "    return df\n",
        "reduce_mem_usage(df_subset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0ce3cb9c",
      "metadata": {
        "id": "0ce3cb9c"
      },
      "outputs": [],
      "source": [
        "df_subset[\"avg_volume_by_state\"] = df_subset.groupby([\"day\", \"state_id\"], observed=True).sales.transform(\"mean\")\n",
        "df_subset[\"avg_volume_by_store\"] = df_subset.groupby([\"day\", \"store_id\"], observed=True).sales.transform(\"mean\")\n",
        "df_subset[\"avg_volume_by_product\"] = df_subset.groupby([\"day\", \"item_id\"], observed=True).sales.transform(\"mean\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "265ddd7d",
      "metadata": {
        "id": "265ddd7d"
      },
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e5f167a4",
      "metadata": {
        "id": "e5f167a4"
      },
      "outputs": [],
      "source": [
        "df_subset[\"avg_volume_by_dept\"] = df_subset.groupby([\"day\", \"dept_id\"], observed=True).sales.transform(\"mean\")\n",
        "df_subset[\"log_num_sold\"] = np.log(df_subset.sales + 1e-8)\n",
        "df_subset[\"avg_volume_by_category\"] = df_subset.groupby([\"day\", \"cat_id\"], observed=True).sales.transform(\"mean\")\n",
        "gc.collect()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "27ac7bfc",
      "metadata": {
        "id": "27ac7bfc"
      },
      "outputs": [],
      "source": [
        "df_subset.dtypes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8ae3dd61",
      "metadata": {
        "id": "8ae3dd61"
      },
      "outputs": [],
      "source": [
        "df_subset[\"wm_yr_wk\"] = df_subset.wm_yr_wk.astype(str).str[-2:].astype(\"category\") \n",
        "df_subset[\"snap_CA\"] = df_subset.snap_CA.astype(str).astype(\"category\") \n",
        "df_subset[\"snap_TX\"] = df_subset.snap_TX.astype(str).astype(\"category\") \n",
        "df_subset[\"snap_WI\"] = df_subset.snap_WI.astype(str).astype(\"category\") \n",
        "df_subset[\"wday\"] = df_subset.wday.astype(str).astype(\"category\")\n",
        "df_subset[\"month\"] = df_subset.month.astype(str).astype(\"category\")\n",
        "df_subset[\"item_id\"] = df_subset.item_id.astype(str).astype(\"category\")\n",
        "df_subset[\"dept_id\"] = df_subset.dept_id.astype(str).astype(\"category\")\n",
        "df_subset[\"store_id\"] = df_subset.store_id.astype(str).astype(\"category\")\n",
        "df_subset[\"cat_id\"] = df_subset.cat_id.astype(str).astype(\"category\")\n",
        "df_subset[\"state_id\"] = df_subset.state_id.astype(str).astype(\"category\")\n",
        "df_subset[\"sales\"] = df_subset.sales.astype(np.float16)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0d8d54a9",
      "metadata": {
        "id": "0d8d54a9"
      },
      "outputs": [],
      "source": [
        "df_subset.isna().sum(0)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_subset.replace(np.NaN,\"normal\",inplace=True)"
      ],
      "metadata": {
        "id": "D_hXfno9kV0R"
      },
      "id": "D_hXfno9kV0R",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_subset.dtypes"
      ],
      "metadata": {
        "id": "ShpunjJ-knWQ"
      },
      "id": "ShpunjJ-knWQ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ad72a934",
      "metadata": {
        "id": "ad72a934"
      },
      "outputs": [],
      "source": [
        "train= df_subset[df_subset['day']<=1941]\n",
        "test=df_subset[df_subset['day']>1941]\n",
        "\n",
        "max_prediction_length = 28\n",
        "max_encoder_length = 472\n",
        "training_cutoff = train[\"day\"].max() - max_prediction_length\n",
        "\n",
        "# Let's create a Dataset\n",
        "training = TimeSeriesDataSet(\n",
        "    train[lambda x: x.day <= training_cutoff],\n",
        "    time_idx=\"day\",\n",
        "    target=\"sales\",\n",
        "    group_ids=[ \"store_id\", \"dept_id\",\"item_id\"], \n",
        "    min_encoder_length=max_prediction_length//2,  # keep encoder length long (as it is in the validation set)\n",
        "    max_encoder_length=max_encoder_length,\n",
        "    min_prediction_length=1,\n",
        "    max_prediction_length=max_prediction_length,\n",
        "    static_categoricals=[ 'state_id','dept_id',\"store_id\", \n",
        "                         \"item_id\",\"snap_CA\",\"snap_TX\",\"snap_WI\"],\n",
        "    time_varying_known_categoricals=[ 'wm_yr_wk', 'wday', 'month'\n",
        "                                      ],\n",
        "    #variable_groups={\"is_holiday\": [\"is_holiday\"]},  # group of categorical variables can be treated as one variable\n",
        "    time_varying_known_reals=[\"day\",\"sell_price\"],\n",
        "    time_varying_unknown_categoricals=[],\n",
        "    time_varying_unknown_reals=[\n",
        "        \"sales\", \"log_num_sold\", \"avg_volume_by_state\",\n",
        "        \"avg_volume_by_store\",\"avg_volume_by_category\",\"avg_volume_by_dept\", \"avg_volume_by_product\"\n",
        "    ],\n",
        "    target_normalizer=GroupNormalizer(\n",
        "        groups=[ \"store_id\", \"dept_id\",\"item_id\"], transformation=\"softplus\"\n",
        "    ),  # use softplus and normalize by group\n",
        "\n",
        "    lags={'sales': [7, 14, 28]},\n",
        "    add_encoder_length=True,\n",
        "    add_relative_time_idx=True,\n",
        "    add_target_scales=True,\n",
        "    categorical_encoders={\n",
        "        'item_id':NaNLabelEncoder(add_nan=True),\n",
        "        'wm_yr_wk':NaNLabelEncoder(add_nan=True),\n",
        "      'wday' : NaNLabelEncoder(add_nan=True),\n",
        "        'month':NaNLabelEncoder(add_nan=True)\n",
        "        }\n",
        "    \n",
        ")\n",
        "\n",
        "# create validation set (predict=True) which means to predict the last max_prediction_length points in time\n",
        "# for each series\n",
        "validation = TimeSeriesDataSet.from_dataset(training, train, predict=True, stop_randomization=True)\n",
        "\n",
        "# create dataloaders for model\n",
        "batch_size = 128  # set this between 32 to 128\n",
        "train_dataloader = training.to_dataloader(train=True, batch_size=batch_size, num_workers=0)\n",
        "val_dataloader = validation.to_dataloader(train=False, batch_size=batch_size * 10, num_workers=0)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "actuals = torch.cat([y for x, (y, weight) in iter(val_dataloader)])\n",
        "baseline_predictions = Baseline().predict(val_dataloader)\n",
        "(actuals - baseline_predictions).abs().mean().item()\n",
        "\n",
        "sm = TweedieDevianceScore()\n",
        "print(f\"Median loss for naive prediction on validation: {sm.loss(actuals, baseline_predictions).mean(axis = 1).median().item()}\")"
      ],
      "metadata": {
        "id": "_4ezU9l87ZNx"
      },
      "id": "_4ezU9l87ZNx",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8a445deb",
      "metadata": {
        "id": "8a445deb"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5799247f",
      "metadata": {
        "id": "5799247f"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "638caf10",
      "metadata": {
        "id": "638caf10"
      },
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2dec3614",
      "metadata": {
        "id": "2dec3614"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b1a0297e",
      "metadata": {
        "id": "b1a0297e"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}